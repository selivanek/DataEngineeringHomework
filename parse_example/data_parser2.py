import requests
from bs4 import BeautifulSoup
import pandas as pd


def parse_f1news_working():
    """–†–∞–±–æ—á–∏–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è F1News.ru –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
    url = "https://www.f1news.ru/"

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }

    try:
        print("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ F1News.ru...")
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.content, 'html.parser')

        news = []

        # –í–ê–†–ò–ê–ù–¢ 1: –ï—Å–ª–∏ –µ—Å—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ –±–ª–æ–∫–∏
        news_blocks = soup.select('article, .news-item, .b-news-item, [class*="news"]')

        if news_blocks:
            print(f"üéØ –ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤: {len(news_blocks)}")

            for block in news_blocks:
                try:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                    title_elem = block.find(['h1', 'h2', 'h3', 'h4']) or block.find('a')
                    title = title_elem.get_text(strip=True) if title_elem else None

                    if not title or len(title) < 10:
                        continue

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Å—ã–ª–∫—É
                    link_elem = block.find('a', href=True)
                    link = link_elem['href'] if link_elem else None
                    if link and link.startswith('/'):
                        link = "https://www.f1news.ru" + link

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
                    desc_elem = block.find('p') or block.find(class_=lambda x: x and ('desc' in x or 'text' in x))
                    description = desc_elem.get_text(strip=True) if desc_elem else None

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    img_elem = block.find('img')
                    image = img_elem.get('src') if img_elem else None
                    if image and image.startswith('//'):
                        image = 'https:' + image
                    elif image and image.startswith('/'):
                        image = 'https://www.f1news.ru' + image

                    news.append({
                        "title": title,
                        "ref": link,
                        "content_small": description,
                        "image": image
                    })

                except Exception as e:
                    continue

        # –í–ê–†–ò–ê–ù–¢ 2: –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –±–ª–æ–∫–∏, –∏—â–µ–º –ø–æ —Å—Å—ã–ª–∫–∞–º
        if not news:
            print("üîç –ò—â–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ —Å—Å—ã–ª–∫–∞–º...")
            all_links = soup.find_all('a', href=True)

            for link in all_links:
                try:
                    title = link.get_text(strip=True)
                    href = link['href']

                    # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ —Å—Å—ã–ª–∫–∏
                    if (title and len(title) > 20 and
                            ('f1' in href.lower() or 'news' in href.lower()) and
                            not any(word in title.lower() for word in ['—á–∏—Ç–∞—Ç—å', '–ø–æ–¥—Ä–æ–±–Ω–µ–µ', '–≤—Å–µ', '...']) and
                            not href.startswith(('javascript:', 'mailto:', '#'))):

                        # –î–µ–ª–∞–µ–º —Å—Å—ã–ª–∫—É –∞–±—Å–æ–ª—é—Ç–Ω–æ–π
                        if href.startswith('/'):
                            href = "https://www.f1news.ru" + href
                        elif not href.startswith('http'):
                            href = "https://www.f1news.ru/" + href

                        # –ò—â–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ —Ä—è–¥–æ–º —Å–æ —Å—Å—ã–ª–∫–æ–π
                        description = None
                        parent = link.parent
                        if parent:
                            paragraphs = parent.find_all('p')
                            for p in paragraphs:
                                text = p.get_text(strip=True)
                                if text and text != title and len(text) > 30:
                                    description = text
                                    break

                        news.append({
                            "title": title,
                            "ref": href,
                            "content_small": description,
                            "image": None
                        })

                        if len(news) >= 15:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
                            break

                except Exception:
                    continue

        # –°–æ–∑–¥–∞–µ–º DataFrame
        df = pd.DataFrame(news)

        if not df.empty:
            print(f"‚úÖ –£–°–ü–ï–•! –ü–æ–ª—É—á–µ–Ω–æ {len(df)} –Ω–æ–≤–æ—Å—Ç–µ–π!")
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            df = df.drop_duplicates(subset=['title', 'ref'])
            print(f"üìä –ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(df)} –Ω–æ–≤–æ—Å—Ç–µ–π")
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –Ω–æ–≤–æ—Å—Ç–∏")

        return df

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
        return pd.DataFrame()


# –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–µ—Ä
data = parse_f1news_working()

if not data.empty:
    print("\nüì∞ –ü–û–°–õ–ï–î–ù–ò–ï –ù–û–í–û–°–¢–ò F1:")
    print("=" * 80)
    for idx, row in data.head(10).iterrows():
        print(f"{idx + 1}. {row['title']}")
        print(f"   üîó {row['ref']}")
        if row['content_small']:
            print(f"   üìù {row['content_small'][:100]}...")
        if row['image']:
            print(f"   üñºÔ∏è {row['image']}")
        print()
else:
    print("üòû –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å F1News.ru")


